<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AIoT æ‰‹å‹¢ç„¡äººæ©Ÿæ§åˆ¶ç³»çµ± - é–‹ç™¼èˆ‡é™¤éŒ¯å…¨ç´€éŒ„</title>
    <style>
        :root {
            --bg-color: #1e1e2e;
            --text-color: #cdd6f4;
            --primary-color: #89b4fa;
            --secondary-color: #f38ba8;
            --accent-color: #a6e3a1;
            --code-bg: #181825;
            --border-color: #313244;
            --sidebar-width: 280px; /* å›ºå®šå·¦å´æ¬„å¯¬åº¦ */
        }
        
        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            margin: 0;
            padding: 0;
            display: flex; /* ä½¿ç”¨ Flexbox åˆ‡å‰²å·¦å³å€å¡Š */
        }
        
        /* --- å·¦å´å›ºå®šå°è¦½åˆ— (Sidebar) --- */
        .sidebar {
            position: fixed;
            top: 0;
            left: 0;
            width: var(--sidebar-width);
            height: 100vh; /* ä½”æ»¿å…¨è¢å¹•é«˜åº¦ */
            background-color: var(--code-bg);
            border-right: 1px solid var(--border-color);
            padding: 30px 20px;
            box-sizing: border-box;
            overflow-y: auto;
            z-index: 1000;
        }

        /* é¦–é è·³è½‰æŒ‰éˆ•å°ˆå±¬æ¨£å¼ */
        .home-btn {
            display: block;
            background-color: var(--primary-color);
            color: var(--bg-color) !important;
            text-align: center;
            font-weight: bold;
            padding: 10px;
            border-radius: 6px;
            margin-bottom: 25px;
            text-decoration: none;
            transition: opacity 0.2s;
        }

        .home-btn:hover {
            opacity: 0.85;
            background-color: var(--primary-color) !important;
            padding-left: 10px !important; /* è¦†è“‹ä¸‹æ–¹é€£çµçš„ hover å‹•ç•« */
        }

        .sidebar h3 {
            margin-top: 0;
            color: var(--primary-color);
            font-size: 1.2em;
            border-bottom: 2px solid var(--border-color);
            padding-bottom: 10px;
            margin-bottom: 20px;
        }

        .sidebar ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .sidebar li {
            margin-bottom: 15px;
        }

        .sidebar a {
            color: var(--text-color);
            text-decoration: none;
            font-size: 1em;
            transition: all 0.2s ease;
            display: block;
            padding: 8px 10px;
            border-radius: 6px;
        }

        .sidebar a:hover {
            color: var(--code-bg);
            background-color: var(--accent-color);
            padding-left: 15px;
            font-weight: bold;
        }

        /* --- å³å´ä¸»è¦å…§å®¹å€ (Main Content) --- */
        .content {
            margin-left: var(--sidebar-width); /* é–ƒé¿å·¦å´æ¬„ */
            padding: 40px 5%;
            width: calc(100% - var(--sidebar-width));
            box-sizing: border-box;
        }

        /* --- å…§å®¹æ’ç‰ˆæ¨£å¼ --- */
        h1, h2, h3 { color: var(--primary-color); }
        h1 { border-bottom: 2px solid var(--primary-color); padding-bottom: 10px; margin-top: 0; }
        h2 { 
            margin-top: 60px; 
            border-bottom: 1px solid var(--border-color); 
            padding-bottom: 5px; 
            scroll-margin-top: 30px; /* é»æ“ŠéŒ¨é»æ™‚é ç•™é ‚éƒ¨ç©ºé–“ */
        }
        .highlight { color: var(--secondary-color); font-weight: bold; }
        .success { color: var(--accent-color); font-weight: bold; }
        
        code {
            background-color: var(--code-bg);
            padding: 3px 6px;
            border-radius: 4px;
            font-family: 'Courier New', Courier, monospace;
            color: #fab387;
        }
        
        pre {
            background-color: var(--code-bg);
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            border: 1px solid var(--border-color);
            box-shadow: inset 0 0 10px rgba(0,0,0,0.5);
        }
        
        pre code { background-color: transparent; padding: 0; color: #cdd6f4; }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background-color: var(--code-bg);
            border-radius: 8px;
            overflow: hidden;
        }
        
        th, td {
            padding: 15px;
            border: 1px solid var(--border-color);
            text-align: left;
        }
        
        th { background-color: #313244; color: var(--primary-color); }
        ul.content-list { padding-left: 20px; }
        ul.content-list li { margin-bottom: 8px; }
    </style>
</head>
<body>

    <nav class="sidebar">
        <a href="index.html" class="home-btn">â¬… å›åˆ°ä¸»ç›®éŒ„</a>
        
        <h3>ç« ç¯€æ·å¾‘</h3>
        <ul>
            <li><a href="#wiring">ä¸€ã€ RPi 5 å¯¦é«”æ¥ç·šå°æ‡‰</a></li>
            <li><a href="#uart-config">äºŒã€ UART èˆ‡ 921600 é®‘ç‡è¨­å®š</a></li>
            <li><a href="#env">ä¸‰ã€ ç’°å¢ƒå»ºç½®èˆ‡ä¾è³´å®‰è£</a></li>
            <li><a href="#debug">å››ã€ FW 1.16 é€£ç·šé™¤éŒ¯ SOP</a></li>
            <li><a href="#code">äº”ã€ æ ¸å¿ƒæ‰‹å‹¢æ§åˆ¶ (å¤šåŸ·è¡Œç·’æ¥µé€Ÿç‰ˆ)</a></li>
        </ul>
    </nav>

    <main class="content">
        <h1>AIoT æ‰‹å‹¢ç„¡äººæ©Ÿæ§åˆ¶ç³»çµ± - æ ¸å¿ƒé–‹ç™¼æ–‡ä»¶</h1>
        <p><strong>ç³»çµ±æ¶æ§‹ï¼š</strong> Raspberry Pi 5 (Companion Computer) + Pixhawk 6C (PX4 v1.16) + MediaPipe AI è¦–è¦ºè¾¨è­˜</p>

        <h2 id="wiring">ä¸€ã€ RPi 5 å¯¦é«”æ¥ç·šå°æ‡‰ (UART)</h2>
        <p>Raspberry Pi 5 æ¡ç”¨å…¨æ–°çš„ RP1 æ™¶ç‰‡è™•ç† I/Oã€‚ç‚ºäº†å¯¦ç¾å½±åƒæ§åˆ¶çš„ä½å»¶é²ï¼Œæˆ‘å€‘å¿…é ˆä½¿ç”¨ <strong>921600 æ³¢ç‰¹ç‡ (Baud Rate)</strong>ã€‚</p>
        
        <table>
            <tr>
                <th>æ–¹æ¡ˆ</th>
                <th>RPi 5 ç«¯æ¥å­”</th>
                <th>Pixhawk 6C (TELEM)</th>
                <th>å°æ‡‰çš„ Linux è¨­å‚™åç¨±</th>
            </tr>
            <tr>
                <td><strong>æ–¹æ¡ˆ A</strong> (æ¨è–¦)</td>
                <td><strong>å°ˆç”¨ 3-Pin Debug æ¥å£</strong></td>
                <td>RX / TX / GND</td>
                <td><code>/dev/ttyAMA0</code></td>
            </tr>
            <tr>
                <td><strong>æ–¹æ¡ˆ B</strong></td>
                <td><strong>40-Pin GPIO æ’é‡</strong> (Pin 8: TX, Pin 10: RX, Pin 6: GND)</td>
                <td>RX / TX / GND</td>
                <td><code>/dev/ttyAMA10</code> (éœ€æ›è¼‰ overlay)</td>
            </tr>
        </table>
        <p><span class="highlight">âš ï¸ é›»æºè­¦å‘Šï¼š</span> åš´ç¦ç›´æ¥å¾ Pixhawk TELEM åŸ å–é›»çµ¦ RPi 5ï¼RPi 5 é‹ç®— AI è€—é›»æ¥µå¤§ï¼Œå¿…é ˆä½¿ç”¨ç¨ç«‹ Type-C ä¾›é›»ï¼ŒPixhawk å‰‡ç”±å‹•åŠ›é›»æ± ä¾›é›»ã€‚å…©è€…<strong>å¿…é ˆå…±åœ° (GND)</strong> é€šè¨Šæ‰æœƒç©©å®šã€‚</p>

        <h2 id="uart-config">äºŒã€ UART èˆ‡ 921600 æ³¢ç‰¹ç‡è¨­å®š</h2>
        
        <h3>1. RPi 5 ç³»çµ±è¨­å®š</h3>
        <p>ç·¨è¼¯ boot åƒæ•¸æª”ï¼š</p>
        <pre><code>sudo nano /boot/firmware/config.txt</code></pre>
        <p><strong>è‹¥ä½¿ç”¨ 40-Pin GPIO (æ–¹æ¡ˆ B)ï¼š</strong></p>
        <p>åŠ å…¥ä»¥ä¸‹æŒ‡ä»¤ä»¥å•Ÿç”¨ RP1 æ™¶ç‰‡ä¸Šçš„ UART0ï¼Œä¸¦é—œé–‰é è¨­çš„ Serial Console é¿å…çµ‚ç«¯æ©Ÿå¹²æ“¾ï¼š</p>
        <pre><code>enable_uart=1
dtoverlay=uart0-pi5</code></pre>
        <p><em>(ä¿®æ”¹å¾Œéœ€ Rebootï¼Œç³»çµ±ä¸­å°‡å‡ºç¾ <code>/dev/ttyAMA10</code> ä¾› Python å‘¼å«)</em></p>

        <h3>2. Pixhawk (QGC) ç«¯ 921600 è¨­å®š</h3>
        <p>ç‚ºåŒ¹é… RPi 5 çš„é«˜é€Ÿå‚³è¼¸ï¼Œé£›æ§ç«¯å¿…é ˆç²¾æº–è¨­å®šï¼š</p>
        <ul class="content-list">
            <li>æ‰“é–‹ QGC é€²å…¥åƒæ•¸è¨­å®š (Parameters)ã€‚</li>
            <li>ç¢ºèªæ¥ç·šçš„ TELEM åŸ  (å¦‚ TELEM 1)ã€‚</li>
            <li>æœå°‹ <code>SER_TEL1_BAUD</code>ï¼Œå°‡å…¶ä¿®æ”¹ç‚º <strong>921600 8N1</strong>ã€‚</li>
            <li>é‡å•Ÿ Pixhawkã€‚</li>
        </ul>

        <h2 id="env">ä¸‰ã€ ç’°å¢ƒå»ºç½®èˆ‡ä¾è³´å®‰è£ (Environment Setup)</h2>
        <p>åœ¨ Raspberry Pi OS (Bookworm, 64-bit) ä¸‹ï¼Œç‚ºé¿å… Numpy 2.0 å¤§æ”¹ç‰ˆå°è‡´ OpenCV/MediaPipe åº•å±¤ C API å´©æ½°ï¼Œå¿…é ˆåš´æ ¼é–å®šé»ƒé‡‘ç›¸å®¹ç‰ˆæœ¬ï¼š</p>
        <pre><code># 1. æ›´æ–°ç³»çµ±ä¸¦å®‰è£åŸºç¤è¦–è¦ºå¥—ä»¶ä¾è³´ (è™•ç† OpenCV åœ¨ Wayland ä¸‹çš„é¡¯ç¤ºä¾è³´)
sudo apt update
sudo apt install -y python3-venv libgl1-mesa-glx libglib2.0-0 libqt5gui5

# 2. å»ºç«‹ä¸¦é€²å…¥ Python è™›æ“¬ç’°å¢ƒ
python3 -m venv ~/drone_env
source ~/drone_env/bin/activate

# 3. å‡ç´š pip (é¿å…èˆŠç‰ˆ pip ç„¡æ³•æŠ“å–æœ€æ–°çš„ arm64 wheel)
pip install --upgrade pip

# 4. å®‰è£é»ƒé‡‘ç›¸å®¹ç‰ˆæœ¬çš„ AIoT æ ¸å¿ƒå¥—ä»¶
# âš ï¸ æ¥µåº¦é‡è¦ï¼šå¼·åˆ¶é–å®š numpy < 2.0ï¼Œå¦å‰‡ OpenCV èˆ‡ MediaPipe æœƒå´©æ½°
pip install "numpy==1.26.4"
pip install "mavsdk&gt;=2.5.0"
pip install "mediapipe==0.10.14"
pip install "opencv-python==4.10.0.84"
</code></pre>

        <h2 id="debug">å››ã€ FW 1.16 é€£ç·šè§£é–é™¤éŒ¯ SOP</h2>
        <p>PX4 v1.16 çš„å¥åº·æª¢æŸ¥æ¥µåš´æ ¼ï¼Œè‹¥é‡åˆ°å•é¡Œè«‹ä¾åºæ’æŸ¥ï¼š</p>
        <table>
            <tr>
                <th>éŒ¯èª¤ç¾è±¡</th>
                <th>æ ¹æœ¬åŸå› </th>
                <th>è§£æ±ºæ–¹æ¡ˆ (QGC åƒæ•¸èˆ‡è¨­å®š)</th>
            </tr>
            <tr>
                <td><strong>é¦¬é”ç„¡åæ‡‰</strong><br>(å·²è§£é–ç¶ ç‡ˆä½†ä¸å‹•)</td>
                <td>FW 1.16 å‹•æ…‹æ§åˆ¶åˆ†é… (Control Allocation) æœªé…ç½®ã€‚PWM è…³ä½æœªæ˜ å°„ã€‚</td>
                <td>é€²å…¥ Actuators (åŸ·è¡Œå™¨)ã€‚æ‰‹å‹•å°‡ <code>I/O PWM Out 1~4</code> ç¶å®šè‡³ <code>Motor 1~4</code>ï¼Œä¸¦é‡å•Ÿã€‚</td>
            </tr>
            <tr>
                <td><strong>Offboard åˆ‡æ›è¢«æ‹’</strong><br>(Position missing)</td>
                <td>å®¤å…§ç„¡ GPSï¼Œé£›æ§æ‹’çµ•é€²å…¥éœ€ä½ç½®æ•¸æ“šçš„ <code>Velocity</code> æ¨¡å¼ã€‚</td>
                <td>ç¨‹å¼æ”¹ç”¨ <code>Attitude</code> (æ¨åŠ›) æ§åˆ¶ã€‚<br>QGC åƒæ•¸ <code>COM_ARM_WO_GPS</code> è¨­ç‚º <strong>1</strong>ã€‚</td>
            </tr>
            <tr>
                <td><strong>è§£é–è¢«æ‹’</strong><br>(Health failures)</td>
                <td>å®‰å…¨æŒ‰éˆ•æœªæŒ‰ã€USB ä¾›é›»é™åˆ¶æˆ–ç„¡é™æ§å™¨è¨Šè™Ÿã€‚</td>
                <td><code>CBRK_IO_SAFETY</code> = 22027<br><code>CBRK_USB_CHK</code> = 197848<br><code>COM_RC_IN_MODE</code> = 1</td>
            </tr>
            <tr>
                <td><strong>è§£é–å¾Œç¬é–“åœè½‰</strong></td>
                <td>é™è½åµæ¸¬å™¨èª¤åˆ¤è§¸åœ°ï¼Œç¬é–“å¼·åˆ¶åˆ‡æ–·æ¨åŠ›ã€‚</td>
                <td><code>COM_DISARM_LAND</code> è¨­ç‚º <strong>-1</strong>ï¼Œæˆ–åœ¨ç¨‹å¼ä¸­çµ¦äºˆçªç ´è‡¨ç•Œå€¼çš„å¤§æ¨åŠ›ã€‚</td>
            </tr>
        </table>

        <h2 id="code">äº”ã€ æ ¸å¿ƒæ‰‹å‹¢æ§åˆ¶ç¨‹å¼ç¢¼ (å¤šåŸ·è¡Œç·’é˜²èª¤åˆ¤æ¥µé€Ÿç‰ˆ)</h2>
        <p>æ­¤æ¶æ§‹æ¡ç”¨<strong>è»Ÿç¡¬é«”è§£è€¦</strong>èˆ‡<strong>å¤šåŸ·è¡Œç·’ (Threading)</strong>è¨­è¨ˆï¼Œå…·å‚™ä»¥ä¸‹å·¥æ¥­ç´šå„ªåŒ–ï¼š</p>
        <ul class="content-list">
            <li><strong>ç®—åŠ›è§£è€¦ï¼š</strong>å°‡ MediaPipe ç§»è‡³èƒŒæ™¯ç¨ç«‹åŸ·è¡Œï¼Œä½¿ UI ç•«é¢æ›´æ–°ç‡ (CAM FPS) çªç ´ 60+ï¼Œå¾¹åº•æ¶ˆé™¤ç•«é¢å¡é “ã€‚</li>
            <li><strong>æ»‘å‹•è¦–çª—æŠ•ç¥¨ (Majority Voting)ï¼š</strong>å–éå» 10 å¹€çš„ AI è¾¨è­˜çµæœï¼Œé”åˆ° 80% ç©©å®šåº¦æ‰è§¸ç™¼æ§åˆ¶ï¼Œæœ‰æ•ˆæ¿¾é™¤æ‰‹éƒ¨å¾®å°æ™ƒå‹•èˆ‡é›œè¨Šèª¤åˆ¤ã€‚</li>
            <li><strong>EMA ä½é€šæ¿¾æ³¢ï¼š</strong>é‡å°å‚³è¼¸è‡³ Pixhawk çš„æ¨åŠ›èˆ‡å§¿æ…‹æ•¸å€¼é€²è¡Œå¹³æ»‘åŒ–éæ¸¡ï¼Œé¿å…ç¬é–“é«˜ä½è½å·®æå‚·é›»èª¿ (ESC)ã€‚</li>
            <li><strong>ç©ºé–“æ­»å€ (Deadzone)ï¼š</strong>ç•«é¢ä¸­å¤® 30% è¨­ç‚ºå®‰å…¨æ‡¸åœå€ï¼Œéœ€æ˜ç¢ºè·¨è¶Šè¼”åŠ©ç·šæ‰è§¸ç™¼ Roll å‹•ä½œã€‚</li>
        </ul>
        <pre><code>import os
import time
import asyncio
import threading
import subprocess
import cv2
import numpy as np
import mediapipe as mp
from collections import deque, Counter
from mavsdk import System
from mavsdk.offboard import Attitude, OffboardError

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# --- å…¨åŸŸæ§åˆ¶èˆ‡æ¿¾æ³¢è®Šæ•¸ ---
current_attitude = [0.0, 0.0, 0.0, 0.0] 
is_offboard_active = False
is_drone_connected = False  

def get_fingers_count(hand_lms, label):
    fingers = []
    if label == "Right": fingers.append(hand_lms.landmark[4].x &lt; hand_lms.landmark[3].x)
    else: fingers.append(hand_lms.landmark[4].x &gt; hand_lms.landmark[3].x)
    for tip_id in [8, 12, 16, 20]: fingers.append(hand_lms.landmark[tip_id].y &lt; hand_lms.landmark[tip_id-2].y)
    return sum(fingers)

# ==========================================
# æ ¸å¿ƒå„ªåŒ–ï¼šAI ç¨ç«‹åŸ·è¡Œç·’ (åŠ å…¥ AI FPS è¨ˆç®—)
# ==========================================
class AIProcessorThread(threading.Thread):
    def __init__(self):
        super().__init__(daemon=True)
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(max_num_hands=1, model_complexity=0, min_detection_confidence=0.6)
        
        self.lock = threading.Lock()
        self.frame_to_process = None
        self.results = None
        self.stable_count = 0
        self.stable_dir = "CENTER"
        self.ai_fps = 0.0  # æ–°å¢ï¼šå„²å­˜ AI è™•ç†çš„ FPS
        
        self.gesture_buffer = deque(maxlen=10)
        self.running = True

    def update_frame(self, frame):
        with self.lock:
            self.frame_to_process = frame

    def get_latest_data(self):
        with self.lock:
            return self.results, self.stable_count, self.stable_dir, self.ai_fps

    def run(self):
        pTime_ai = time.time()
        while self.running:
            frame = None
            with self.lock:
                if self.frame_to_process is not None:
                    frame = self.frame_to_process.copy()
                    self.frame_to_process = None 
            
            if frame is None:
                time.sleep(0.005)
                continue

            # --- åŸ·è¡Œè€—æ™‚çš„ AI è¾¨è­˜ ---
            results = self.hands.process(frame)
            
            # --- è¨ˆç®— AI å°ˆå±¬çš„ FPS ---
            cTime_ai = time.time()
            time_diff = cTime_ai - pTime_ai
            current_ai_fps = 1.0 / time_diff if time_diff &gt; 0 else 0
            pTime_ai = cTime_ai

            raw_count = 0
            raw_dir = "CENTER"

            if results and results.multi_hand_landmarks:
                for i, hand_lms in enumerate(results.multi_hand_landmarks):
                    label = results.multi_handedness[i].classification[0].label
                    raw_count = get_fingers_count(hand_lms, label)
                    
                    hand_center_x = hand_lms.landmark[9].x
                    if hand_center_x &gt; 0.65: raw_dir = "RIGHT"
                    elif hand_center_x &lt; 0.35: raw_dir = "LEFT"
                    else: raw_dir = "CENTER"
            
            self.gesture_buffer.append((raw_count, raw_dir))
            
            # --- ç‹€æ…‹æ›´æ–°èˆ‡é˜²èª¤åˆ¤æŠ•ç¥¨ ---
            temp_stable_count = self.stable_count
            temp_stable_dir = self.stable_dir
            if len(self.gesture_buffer) == self.gesture_buffer.maxlen:
                most_common = Counter(self.gesture_buffer).most_common(1)[0]
                if most_common[1] &gt;= 8:
                    temp_stable_count = most_common[0][0]
                    temp_stable_dir = most_common[0][1]
            
            # --- å°‡æ‰€æœ‰çµæœå®‰å…¨åœ°å¯«å› Lock å€ ---
            with self.lock:
                self.results = results
                self.stable_count = temp_stable_count
                self.stable_dir = temp_stable_dir
                self.ai_fps = (self.ai_fps * 0.9) + (current_ai_fps * 0.1)

# ==========================================
# å½±åƒæ“·å–èˆ‡é£›æ§é€£ç·š
# ==========================================
class CameraStream:
    def __init__(self, width=640, height=480, fps=60): 
        self.width, self.height = width, height
        self.frame_size = int(width * height * 1.5)
        self.cmd = ["rpicam-vid", "-t", "0", "--width", str(width), "--height", str(height),
                    "--framerate", str(fps), "--codec", "yuv420", "--nopreview", "-o", "-"]
        self.process = subprocess.Popen(self.cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)
        self.latest_frame_rgb = None
        self.running = True
        self.thread = threading.Thread(target=self._update, daemon=True)
        self.thread.start()

    def _update(self):
        while self.running:
            raw_data = self.process.stdout.read(self.frame_size)
            if len(raw_data) == self.frame_size:
                yuv = np.frombuffer(raw_data, dtype=np.uint8).reshape((int(self.height * 1.5), self.width))
                self.latest_frame_rgb = cv2.cvtColor(yuv, cv2.COLOR_YUV2RGB_I420)

    def read(self): return self.latest_frame_rgb
    def release(self):
        self.running = False
        self.process.terminate()

async def connect_and_monitor(drone):
    global is_drone_connected, is_offboard_active
    try:
        # âš ï¸ éœ€ä¾ç…§ç¡¬é«”æ¥ç·šé¸æ“‡å°æ‡‰çš„ tty æ¥å£ (AMA0 ç‚º Debug Port, AMA10 ç‚º GPIO æ’é‡)
        await drone.connect(system_address="serial:///dev/ttyAMA0:921600") 
        async for state in drone.core.connection_state():
            if state.is_connected and not is_drone_connected:
                print("\nâœ… ç„¡äººæ©Ÿç¡¬é«”å·²é€£ç·šï¼")
                is_drone_connected = True
            elif not state.is_connected and is_drone_connected:
                print("\nâš ï¸ ç„¡äººæ©Ÿå·²æ–·ç·šï¼")
                is_drone_connected = False
                is_offboard_active = False
    except: pass

async def drone_control_loop(drone):
    global current_attitude, is_drone_connected
    while True:
        if is_drone_connected:
            try:
                await drone.offboard.set_attitude(
                    Attitude(current_attitude[0], current_attitude[1], current_attitude[2], current_attitude[3])
                )
            except: pass
        await asyncio.sleep(0.05)

# ==========================================
# ä¸»ç¨‹å¼ (æ¥µé€Ÿ UI è¿´åœˆ)
# ==========================================
async def run():
    global current_attitude, is_offboard_active, is_drone_connected
    
    drone = System()
    asyncio.create_task(connect_and_monitor(drone))
    asyncio.create_task(drone_control_loop(drone))

    ai_thread = AIProcessorThread()
    ai_thread.start()
    
    cap = CameraStream(640, 480, 60)
    mp_hands_draw = mp.solutions.hands 
    pTime, cam_fps = 0, 0

    print("\nğŸš€ é›™æ ¸æ•ˆèƒ½ç›£æ§ç‰ˆå°±ç·’ï¼(å³ä¸Šè§’é¡¯ç¤º UI èˆ‡ AI é›™é‡ FPS)")
    
    try:
        while True:
            frame_rgb = cap.read()
            if frame_rgb is None:
                await asyncio.sleep(0.001)
                continue

            frame_rgb = cv2.flip(frame_rgb, 1)
            ai_thread.update_frame(frame_rgb)
            
            # --- è®€å– AI æœ€æ–°ç‹€æ…‹èˆ‡ AI FPS ---
            results, stable_count, stable_dir, ai_fps = ai_thread.get_latest_data()
            
            frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)
            
            target_att = [0.0, 0.0, 0.0, 0.0]
            target_att[3] = stable_count * 0.10
            
            if stable_dir == "RIGHT": target_att[0] = 15.0  
            elif stable_dir == "LEFT": target_att[0] = -15.0 
            else: target_att[0] = 0.0
            
            status_text = f"T:{int(target_att[3]*100)}% | R:{stable_dir}"

            alpha = 0.05 
            for j in range(4):
                current_attitude[j] = (current_attitude[j] * (1.0 - alpha)) + (target_att[j] * alpha)

            # --- UI FPS è¨ˆç®— ---
            cTime = time.time()
            if (cTime - pTime) &gt; 0:
                cam_fps = (cam_fps * 0.9) + ((1 / (cTime - pTime)) * 0.1)
                pTime = cTime

            if results and results.multi_hand_landmarks:
                for hand_lms in results.multi_hand_landmarks:
                    mp.solutions.drawing_utils.draw_landmarks(frame_bgr, hand_lms, mp_hands_draw.HAND_CONNECTIONS)
            
            h, w, _ = frame_bgr.shape
            cv2.line(frame_bgr, (int(w*0.35), 0), (int(w*0.35), h), (100, 100, 100), 1)
            cv2.line(frame_bgr, (int(w*0.65), 0), (int(w*0.65), h), (100, 100, 100), 1)

            # å·¦å´ç‹€æ…‹é¡¯ç¤º
            mode_text = "AI ACTIVE" if is_offboard_active else "STANDBY"
            cv2.putText(frame_bgr, f"MODE: {mode_text}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            cv2.putText(frame_bgr, f"CMD: {status_text}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

            # å³ä¸Šè§’ç‹€æ…‹é¡¯ç¤º (é€£ç·šã€CAM FPSã€AI FPS)
            conn_status = "FC CONNECTED" if is_drone_connected else "FC DISCONNECTED"
            conn_color = (0, 255, 0) if is_drone_connected else (0, 0, 255)
            cv2.putText(frame_bgr, conn_status, (w - 200, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, conn_color, 2)
            cv2.putText(frame_bgr, f"CAM FPS: {cam_fps:.1f}", (w - 200, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 165, 0), 2)
            cv2.putText(frame_bgr, f"AI  FPS: {ai_fps:.1f}", (w - 200, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

            cv2.imshow('Marlon Drone AI', frame_bgr)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('a'):
                if is_drone_connected:
                    try:
                        await drone.offboard.start()
                        is_offboard_active = True
                    except: pass
            elif key == ord('q'): break
            await asyncio.sleep(0.001)

    finally:
        cap.release()
        ai_thread.running = False
        cv2.destroyAllWindows()

if __name__ == "__main__":
    asyncio.run(run())
</code></pre>
    </main>
</body>
</html>
